{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "# Newspaper classification: ETL\n\nThis ETL notebook includes code to scrape titles from two major German newspaper websites for later feature engineering and classification. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Setup\n\nRelevant libraries are loaded:"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": "from bs4 import BeautifulSoup\nimport requests\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nfrom project_lib import Project"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Scraping newspapers\n\nTitles from newspapers are scraped per newspaper using *BeautifulSoup* and *requests* libraries. \n\n### S\u00fcddeutsche Zeitung (SZ)"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Newspaper</th>\n      <th>DateTime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wie die Bundeswehr nun helfen soll</td>\n      <td>SZ</td>\n      <td>2021-08-16 11:10:29.425187</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Was die R\u00fcckkehr der Taliban bedeutet</td>\n      <td>SZ</td>\n      <td>2021-08-16 11:10:29.425187</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>S\u00f6der: \"Man kann nicht sagen, dass alles perfe...</td>\n      <td>SZ</td>\n      <td>2021-08-16 11:10:29.425187</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "                                               Title Newspaper  \\\n0                 Wie die Bundeswehr nun helfen soll        SZ   \n1              Was die R\u00fcckkehr der Taliban bedeutet        SZ   \n2  S\u00f6der: \"Man kann nicht sagen, dass alles perfe...        SZ   \n\n                    DateTime  \n0 2021-08-16 11:10:29.425187  \n1 2021-08-16 11:10:29.425187  \n2 2021-08-16 11:10:29.425187  "
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Scrape website\nsz_url = \"https://www.sueddeutsche.de/\"\nsz_html_page = requests.get(sz_url)\nsz_soup = BeautifulSoup(sz_html_page.content, \"html.parser\")\n\n# Extract titles\nsz_teasers = sz_soup.find_all(class_=\"sz-teaser__text-container--s\")\nsz_titles = []\nfor teaser in sz_teasers:\n    title_element = teaser.find(\"h3\", class_=\"sz-teaser__title\")\n    sz_titles.append(title_element.text)\n    \n# Save as df and initialise newspaper name and date\nsz_df = pd.DataFrame(sz_titles, columns =['Title'])\nsz_df['Newspaper'] = \"SZ\"\nsz_df['DateTime'] = datetime.now()\n\nsz_df.head(3)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Welt"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Newspaper</th>\n      <th>DateTime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\u201eBiden sagte: ,Sch*** drauf, das ist doch nic...</td>\n      <td>Welt</td>\n      <td>2021-08-16 11:10:29.814123</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Deutsche Botschaft warnte offenbar lange erfo...</td>\n      <td>Welt</td>\n      <td>2021-08-16 11:10:29.814123</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Man steht ohnm\u00e4chtig vor dieser kolossalen Ni...</td>\n      <td>Welt</td>\n      <td>2021-08-16 11:10:29.814123</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "                                               Title Newspaper  \\\n0   \u201eBiden sagte: ,Sch*** drauf, das ist doch nic...      Welt   \n1   Deutsche Botschaft warnte offenbar lange erfo...      Welt   \n2   Man steht ohnm\u00e4chtig vor dieser kolossalen Ni...      Welt   \n\n                    DateTime  \n0 2021-08-16 11:10:29.814123  \n1 2021-08-16 11:10:29.814123  \n2 2021-08-16 11:10:29.814123  "
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Scrape website\nwelt_url = \"https://www.welt.de/\"\nwelt_html_page = requests.get(welt_url)\nwelt_soup = BeautifulSoup(welt_html_page.content, \"html.parser\")\n\n# Extract titles\nwelt_teasers = welt_soup.find_all(class_=\"c-teaser-default__body o-teaser__body\")\nwelt_titles = []\n\nfor teaser in welt_teasers:\n    title_element = teaser.find(attrs={'data-qa': 'Teaser.Link'})\n    welt_titles.append(title_element.text)\n\n# Save as df and initialise newspaper name and date\nwelt_df = pd.DataFrame(welt_titles, columns =['Title'])\nwelt_df['Newspaper'] = \"Welt\"\nwelt_df['DateTime'] = datetime.now()\n\nwelt_df.head(3)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Concatenation\n\nData from *SZ* and *Welt* newspapers is combined, which now looks as follows:"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Newspaper</th>\n      <th>DateTime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wie die Bundeswehr nun helfen soll</td>\n      <td>SZ</td>\n      <td>2021-08-16 11:10:29.425187</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Was die R\u00fcckkehr der Taliban bedeutet</td>\n      <td>SZ</td>\n      <td>2021-08-16 11:10:29.425187</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>S\u00f6der: \"Man kann nicht sagen, dass alles perfe...</td>\n      <td>SZ</td>\n      <td>2021-08-16 11:10:29.425187</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Rein in etablierte Machtstrukturen</td>\n      <td>SZ</td>\n      <td>2021-08-16 11:10:29.425187</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Neuer Impfstoff, neue \u00c4ngste</td>\n      <td>SZ</td>\n      <td>2021-08-16 11:10:29.425187</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "                                               Title Newspaper  \\\n0                 Wie die Bundeswehr nun helfen soll        SZ   \n1              Was die R\u00fcckkehr der Taliban bedeutet        SZ   \n2  S\u00f6der: \"Man kann nicht sagen, dass alles perfe...        SZ   \n3                 Rein in etablierte Machtstrukturen        SZ   \n4                       Neuer Impfstoff, neue \u00c4ngste        SZ   \n\n                    DateTime  \n0 2021-08-16 11:10:29.425187  \n1 2021-08-16 11:10:29.425187  \n2 2021-08-16 11:10:29.425187  \n3 2021-08-16 11:10:29.425187  \n4 2021-08-16 11:10:29.425187  "
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df = pd.concat([sz_df, welt_df])\ndf.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Updating Data\n\nData from current website scraping is combined with older data:"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": "project = Project(project_id = project_id, project_access_token = project_token)"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "old_file = project.get_file(\"Newspaper_Data.csv\")\nold_file.seek(0)\nold_df = pd.read_csv(old_file)"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": "df = pd.concat([df, old_df])"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Duplicate titles per newspaper (i.e., that appeared on multiple occasions) are deleted per newspaper with older title kept:"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": "df = df.drop_duplicates(subset=['Title', 'Newspaper'], keep='last')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Saving\n\nData is saved for feature engineering and other downstream processing:"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "{'file_name': 'Newspaper_Data.csv',\n 'message': 'File saved to project storage.',\n 'bucket_name': 'newspaperclassification-donotdelete-pr-htkved6zqhsjcj',\n 'asset_id': '87fae567-81e7-4f99-954e-a18d2da8c26e'}"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "project.save_data(file_name = \"Newspaper_Data.csv\", data = df.to_csv(index = False), set_project_asset=True, overwrite=True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}